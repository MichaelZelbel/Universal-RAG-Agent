{
  "name": "PAC Builder",
  "nodes": [
    {
      "parameters": {
        "promptType": "define",
        "text": "=Analyze if this conversation contains information worth remembering long-term.\n\nCurrent context:\n={{ $json.context }}\n\nLatest exchange:\nUser: {{ $json.userMessage }}\nAssistant: {{ $json.assistantResponse }}\n\nRespond with ONLY valid JSON:\n{\"should_update\": true, \"new_memories\": [{\"type\": \"preference\", \"content\": \"User likes pizza\"}], \"remove_indices\": []}\n\nOnly create memories for important lasting information (preferences, facts, goals). Not for casual greetings.",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        688,
        -80
      ],
      "id": "acad580d-9772-4f81-af4a-29356b59dc70",
      "name": "Memory Manager"
    },
    {
      "parameters": {
        "jsCode": "// Build context with all summaries (including gap-filled)\nconst trigger = $('Start').first().json || {};\nconst mergedData = $('Merge Gap Summary').first().json;\nconst transcriptRows = mergedData.transcript_rows || [];\nconst summaryRows = mergedData.summary_rows || [];\n\n// Sort transcript\nconst rows = transcriptRows\n  .filter(r => !r.context_id || String(r.context_id) === String(trigger.context_id))\n  .sort((a, b) => {\n    const ts = v => Date.parse(v || '') || 0;\n    return ts(a.created_at || a.createdAt) - ts(b.created_at || b.createdAt);\n  });\n\n// Format recent messages\nconst recent_messages = rows.map(r => {\n  const message = String(r.message ?? r.message_original ?? '').trim();\n  const original = String(r.message_original ?? '').trim();\n  \n  return {\n    id: r.id,\n    role: r.role === 'assistant' ? 'assistant' : 'user',\n    content: message,\n    was_truncated: original.length > 0 && message !== original\n  };\n});\n\n// Format summaries (oldest to newest)\nconst topic_summaries = summaryRows.map(s => ({\n  topic_title: s.topic_title || '',\n  summary: s.topic_summary || '',\n  message_range: [s.first_message_id, s.last_message_id],\n  message_count: s.message_count || 0\n}));\n\n// Get long-term memories\nlet long_term_memories = [];\ntry {\n  if (trigger.context && typeof trigger.context === 'string') {\n    const parsed = JSON.parse(trigger.context);\n    if (Array.isArray(parsed?.long_term_memories)) {\n      long_term_memories = parsed.long_term_memories;\n    }\n  } else if (trigger.context && typeof trigger.context === 'object' &&\n             Array.isArray(trigger.context.long_term_memories)) {\n    long_term_memories = trigger.context.long_term_memories;\n  }\n} catch { /* ignore */ }\n\nconst context = { \n  topic_summaries,\n  recent_messages, \n  long_term_memories \n};\n\nreturn [{\n  json: {\n    context_id: String(trigger.context_id || ''),\n    context: JSON.stringify(context),\n    userMessage: String(trigger.userMessage ?? ''),\n    assistantResponse: String(trigger.assistantResponse ?? '')\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4512,
        -64
      ],
      "id": "a39e126b-decf-496b-88d5-1ecdbb57d931",
      "name": "Build Next Context"
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst MESSAGE_LENGTH_THRESHOLD = 5000;\nconst TRUNCATE_LENGTH = 1000;\nconst TRUNCATION_SUFFIX = '... [truncated] Message Summary: ';\n\n// Get input data from trigger\nconst triggerData = $('Start').first().json;\nconst contextId = triggerData.context_id;\nconst userMessage = triggerData.userMessage;\nconst assistantResponse = triggerData.assistantResponse;\nconst tablePrefix = triggerData.table_prefix;\nconst contextStr = triggerData.context;\n\n// Process user message\nlet userItem = null;\nif (typeof userMessage === 'string' && userMessage.trim()) {\n  const originalMessage = userMessage.trim();\n  const messageLength = originalMessage.length;\n  \n  userItem = {\n    context_id: contextId,\n    table_prefix: tablePrefix,\n    context: contextStr,\n    role: 'user',\n    message_original: originalMessage,\n    needs_summary: messageLength > MESSAGE_LENGTH_THRESHOLD,\n    truncated_message: messageLength > MESSAGE_LENGTH_THRESHOLD \n      ? originalMessage.substring(0, TRUNCATE_LENGTH) + TRUNCATION_SUFFIX\n      : null,\n    message: messageLength <= MESSAGE_LENGTH_THRESHOLD ? originalMessage : null\n  };\n}\n\n// Process assistant message\nlet assistantItem = null;\nif (typeof assistantResponse === 'string' && assistantResponse.trim()) {\n  const originalMessage = assistantResponse.trim();\n  const messageLength = originalMessage.length;\n  \n  assistantItem = {\n    context_id: contextId,\n    table_prefix: tablePrefix,\n    context: contextStr,\n    role: 'assistant',\n    message_original: originalMessage,\n    needs_summary: messageLength > MESSAGE_LENGTH_THRESHOLD,\n    truncated_message: messageLength > MESSAGE_LENGTH_THRESHOLD \n      ? originalMessage.substring(0, TRUNCATE_LENGTH) + TRUNCATION_SUFFIX\n      : null,\n    message: messageLength <= MESSAGE_LENGTH_THRESHOLD ? originalMessage : null\n  };\n}\n\n// Return items for processing\nconst items = [];\nif (userItem) items.push({ json: userItem });\nif (assistantItem) items.push({ json: assistantItem });\n\nreturn items;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1040,
        -80
      ],
      "id": "0f0e0f4f-b7ad-4726-aedd-592f7d28cdd8",
      "name": "Prepare Messages"
    },
    {
      "parameters": {
        "conditions": {
          "boolean": [
            {
              "value1": "={{ $json.needs_summary }}",
              "value2": true
            }
          ]
        }
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 1,
      "position": [
        1248,
        -80
      ],
      "id": "6c273dac-5d5a-4cb6-a6c4-150b63b0ea7e",
      "name": "Check If Summary Needed"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Create a concise summary of the following message. The summary MUST be 1000 characters or less. Focus on the key points and main ideas.\n\nOriginal message:\n{{ $json.message_original }}\n\nProvide ONLY the summary text, no additional formatting or explanation.",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        1456,
        -272
      ],
      "id": "c7d622cd-af96-487e-81fc-87656ec03808",
      "name": "Summarize Long Message"
    },
    {
      "parameters": {
        "jsCode": "// === Combine Message with Summary (per item) ===\n\n// Direct agent summary from previous node\nconst summary = String($input.item?.json?.output ?? '').trim();\n\n// Nearby items on the same branch (if present)\nconst paired = (name) => { try { return ($item(name, 0)?.json ?? {}); } catch { return {}; } };\nconst cur    = $json ?? {};\nconst merged = paired('Merge Messages');            // rename if needed\nconst prep   = paired('Prepare Transcript Rows');   // rename if needed\n\n// Role: from the current item first\nconst role = String(cur.role ?? merged.role ?? prep.role ?? 'user').trim();\n\n// Trigger payload (never used for role, only as last-resort text)\nconst trigger = $('Start').first().json || {};\nconst triggerMessage =\n  role === 'assistant'\n    ? String(trigger.assistantResponse ?? '')\n    : String(trigger.userMessage ?? '');\n\n// Original message: current item -> nearby items -> trigger (role-aware)\nconst originalRaw =\n  cur.message_original ?? cur.message ??\n  merged.message_original ?? merged.message ??\n  prep.message_original ?? prep.message ??\n  triggerMessage;\n\nconst original = String(originalRaw ?? '').trim();\n\n// Minimal required meta\nconst context_id   = String(cur.context_id   ?? merged.context_id   ?? prep.context_id   ?? trigger.context_id ?? '');\nconst table_prefix = String(cur.table_prefix ?? merged.table_prefix ?? prep.table_prefix ?? trigger.table_prefix ?? '');\nconst context      = (cur.context ?? merged.context ?? prep.context ?? trigger.context ?? null);\n\n// Build combined message\nconst MAX = 1000;\nconst SUFFIX = ' ... [truncated] Message Summary: ';\nconst finalMessage = original.slice(0, MAX) + SUFFIX + summary;\n\n// Output with message_original populated\nreturn {\n  json: {\n    context_id,\n    table_prefix,\n    context,\n    role,\n    message_original: original,\n    message: finalMessage,\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1760,
        -272
      ],
      "id": "ff4bf0c2-f6f0-42fb-a201-548ccbe84613",
      "name": "Combine Message with Summary"
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Message doesn't need summary, use original as-is\n// Pass through all context data\nreturn {\n  json: {\n    context_id: $json.context_id,\n    table_prefix: $json.table_prefix,\n    context: $json.context,\n    role: $json.role,\n    message_original: $json.message_original,\n    message: $json.message\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1760,
        -64
      ],
      "id": "c513ccbf-9117-43c6-a46a-d4167a799970",
      "name": "Use Original Message"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.merge",
      "typeVersion": 2.1,
      "position": [
        1968,
        -80
      ],
      "id": "ace46793-a99c-4f3e-87cf-68805a1f36c3",
      "name": "Merge Messages"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4o-mini",
          "mode": "list",
          "cachedResultName": "gpt-4o-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        688,
        160
      ],
      "id": "ef15db6d-f0fa-4745-8a43-629551666853",
      "name": "OpenAI Chat Model1",
      "credentials": {
        "openAiApi": {
          "id": "ypHiVnbB3jkc0yAx",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4o-mini",
          "mode": "list",
          "cachedResultName": "gpt-4o-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        1456,
        -128
      ],
      "id": "a19fcfda-a3bb-4fd3-835e-c7650a2719cd",
      "name": "OpenAI Chat Model2",
      "credentials": {
        "openAiApi": {
          "id": "ypHiVnbB3jkc0yAx",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "content": "Fixed Message Processing:\n- Messages > 5000 chars get truncated + AI summary\n- Original stored in message_original\n- Processed version in message column\n- Context data properly passed through all nodes\n- Fixed item pairing issues after merge\n\nENHANCEMENT:\n- Each message in context now includes database ID\n- Added 'was_truncated' flag to indicate if full message is in DB\n- Agent can retrieve original messages using ID when needed",
        "height": 240,
        "width": 350
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1040,
        -400
      ],
      "typeVersion": 1,
      "id": "41f363df-5581-47bd-97d2-d4d1a1864554",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO {{ $('Start').first().json.table_prefix }}chat_transcript\n(context_id, role, message, message_original) VALUES (\n  '{{ String( $('Start').first().json.context_id).replace(/'/g, \"''\") }}',\n  '{{ String($json.role).replace(/'/g, \"''\") }}',\n  '{{ String($json.message).replace(/'/g, \"''\") }}',\n  '{{ String($json.message_original).replace(/'/g, \"''\") }}'\n);\n",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        2160,
        -80
      ],
      "id": "1ea58ca5-a405-4532-900e-d83445f09e0a",
      "name": "Insert Transcript",
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "p1yb7OdsllaTAj7J",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT\n  id, context_id, role, message, message_original, created_at, updated_at\nFROM {{ $('Start').first().json.table_prefix }}chat_transcript\nWHERE context_id = '{{ $('Start').first().json.context_id }}'\nORDER BY created_at DESC\nLIMIT 20;",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        2352,
        -80
      ],
      "id": "2fb2682a-f4d6-49ce-b3f4-a1a95f3379c6",
      "name": "Fetch Transcript",
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "p1yb7OdsllaTAj7J",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT\n  id,\n  topic_title,\n  topic_summary,\n  first_message_id,\n  last_message_id,\n  message_count,\n  created_at\nFROM {{ $('Start').first().json.table_prefix }}chat_topic_summaries\nWHERE context_id = '{{ $('Start').first().json.context_id }}'\n  AND last_message_id < (\n    SELECT MIN(id) FROM (\n      SELECT id FROM {{ $('Start').first().json.table_prefix }}chat_transcript\n      WHERE context_id = '{{ $('Start').first().json.context_id }}'\n      ORDER BY created_at DESC\n      LIMIT 10\n    ) recent\n  )\nORDER BY last_message_id DESC\nLIMIT 10;",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        2576,
        -80
      ],
      "id": "5a89cf5c-e6e2-4210-b965-b74d191946c3",
      "name": "Fetch Topic Summaries",
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "p1yb7OdsllaTAj7J",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO {{ $('Start').first().json.table_prefix }}chat_contexts\n(context_id, context)\nVALUES (\n  '{{ $json.context_id }}',\n  COALESCE(\n    NULLIF($$\n      {{ typeof $json.context === 'string'\n          ? $json.context\n          : JSON.stringify($json.context || {}) }}\n    $$, '')::jsonb,\n    '{}'::jsonb\n  )\n)\nON CONFLICT (context_id) DO UPDATE SET\n  context    = EXCLUDED.context,\n  \"updated_at\" = timezone('utc'::text, now());\n",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        4704,
        -64
      ],
      "id": "cfd97c48-9580-4f78-9e86-fb0982564930",
      "name": "Upsert Context",
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "p1yb7OdsllaTAj7J",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT id, role, message, created_at\nFROM {{ $('Start').first().json.table_prefix }}chat_transcript\nWHERE context_id = '{{ $('Start').first().json.context_id }}'\nORDER BY created_at DESC\nLIMIT 5;",
        "options": {
          "queryReplacement": ""
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        2352,
        128
      ],
      "id": "af362f0b-badc-4ac9-a7f0-d6531e91c551",
      "name": "Fetch Recent for Detection",
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "p1yb7OdsllaTAj7J",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.detection_prompt }}",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        2768,
        128
      ],
      "id": "f5cd3045-1256-4424-9a33-16960fe0d44a",
      "name": "Detect Topic Shift"
    },
    {
      "parameters": {
        "jsCode": "// Process topic detection result\nconst trigger = $('Start').first().json || {};\nconst aiOutput = $json.output || '{}';\n\n// Parse AI response\nlet result = { is_topic_shift: false, confidence: 0, new_topic_name: null, reasoning: '' };\ntry {\n  const cleaned = aiOutput\n    .replace(/```json\\n?/g, '')\n    .replace(/```\\n?/g, '')\n    .trim();\n  result = JSON.parse(cleaned);\n} catch (e) {\n  console.log('Failed to parse AI response:', aiOutput);\n}\n\nconst CONFIDENCE_THRESHOLD = 0.7;\nconst isShift = result.is_topic_shift && result.confidence >= CONFIDENCE_THRESHOLD;\n\n// Log the result\nconsole.log('=== TOPIC DETECTION ===' );\nconsole.log('Context ID:', trigger.context_id);\nconsole.log('Topic Shift:', isShift);\nconsole.log('Confidence:', result.confidence);\nconsole.log('New Topic:', result.new_topic_name);\nconsole.log('Reasoning:', result.reasoning);\nif (isShift) {\n  console.log('⚠️  TOPIC CHANGED - State will be reset');\n} else {\n  console.log('✓ Continuing current topic');\n}\nconsole.log('=======================');\n\n// Pass through for state update\nreturn [{\n  json: {\n    context_id: trigger.context_id,\n    topic_shift_detected: isShift,\n    shift_confidence: result.confidence,\n    suggested_topic_name: result.new_topic_name || 'Untitled Topic',\n    shift_reasoning: result.reasoning\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3056,
        128
      ],
      "id": "747e13b4-9820-45a5-aee8-3ad9029600f8",
      "name": "Log Detection Result"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-mini",
          "mode": "list",
          "cachedResultName": "gpt-4.1-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        2768,
        336
      ],
      "id": "f7b3a218-28f5-4f20-8fcd-e8efe87be1b6",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "ypHiVnbB3jkc0yAx",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Combine all data for a SINGLE detection call\nconst trigger = $('Start').first().json || {};\nconst recentMessages = $input.all().map(i => i.json || {});\n\n// Format recent messages (excluding the new ones we just added)\nconst contextMessages = recentMessages\n  .filter(m => m.id) // has ID = already in DB\n  .sort((a, b) => a.id - b.id) // oldest to newest\n  .slice(0, -2) // exclude last 2 (the ones we just inserted)\n  .map(m => `${m.role}: ${m.message}`)\n  .join('\\n');\n\n// The NEW exchange we're analyzing\nconst newUserMsg = trigger.userMessage || '';\nconst newAssistantMsg = trigger.assistantResponse || '';\n\n// Build prompt\nconst prompt = `Analyze if this new exchange is a topic shift from previous conversation.\n\nPrevious context:\n${contextMessages || 'No previous messages'}\n\nNew exchange to analyze:\nuser: ${newUserMsg}\nassistant: ${newAssistantMsg}\n\nDid the topic change? Respond ONLY with JSON:\n{\n  \"is_topic_shift\": true or false,\n  \"confidence\": 0.0 to 1.0,\n  \"new_topic_name\": \"3-5 words\" or null,\n  \"reasoning\": \"one sentence\"\n}\n\nRules: shift = NEW subject. NOT shift = continuation of same subject.`;\n\nreturn [{\n  json: {\n    context_id: trigger.context_id,\n    detection_prompt: prompt\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2576,
        128
      ],
      "id": "73992140-967a-4976-bf84-ea476ae89f26",
      "name": "Prepare Detection Data"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "-- Get current state before update\nWITH current_state AS (\n  SELECT \n    current_topic_start_id,\n    current_topic_name,\n    messages_in_current_topic\n  FROM {{ $('Start').first().json.table_prefix }}topic_state\n  WHERE context_id = '{{ $json.context_id }}'\n),\nlast_msg AS (\n  SELECT id FROM {{ $('Start').first().json.table_prefix }}chat_transcript\n  WHERE context_id = '{{ $json.context_id }}'\n  ORDER BY created_at DESC\n  LIMIT 1\n)\n-- Insert or update and return info\nINSERT INTO {{ $('Start').first().json.table_prefix }}topic_state\n(context_id, current_topic_start_id, current_topic_name, messages_in_current_topic, last_check_message_id)\nSELECT \n  '{{ $json.context_id }}',\n  CASE \n    WHEN {{ $json.topic_shift_detected }}::boolean THEN (SELECT id FROM last_msg)\n    ELSE COALESCE((SELECT current_topic_start_id FROM current_state), (SELECT id FROM last_msg))\n  END as new_start_id,\n  CASE \n    WHEN {{ $json.topic_shift_detected }}::boolean THEN '{{ String($json.suggested_topic_name || \"New Topic\").replace(/'/g, \"''\") }}'\n    ELSE COALESCE((SELECT current_topic_name FROM current_state), 'Initial Topic')\n  END as new_name,\n  CASE \n    WHEN {{ $json.topic_shift_detected }}::boolean THEN 1\n    ELSE COALESCE((SELECT messages_in_current_topic + 1 FROM current_state), 1)\n  END as new_count,\n  (SELECT id FROM last_msg)\nON CONFLICT (context_id) DO UPDATE SET\n  current_topic_start_id = EXCLUDED.current_topic_start_id,\n  current_topic_name = EXCLUDED.current_topic_name,\n  messages_in_current_topic = EXCLUDED.messages_in_current_topic,\n  last_check_message_id = EXCLUDED.last_check_message_id,\n  updated_at = timezone('utc'::text, now())\nRETURNING \n  (SELECT current_topic_start_id FROM current_state) as previous_topic_start_id,\n  (SELECT current_topic_name FROM current_state) as previous_topic_name,\n  (SELECT messages_in_current_topic FROM current_state) as previous_topic_message_count,\n  current_topic_start_id,\n  context_id,\n  {{ $json.topic_shift_detected }}::boolean as topic_shift_detected;",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        3248,
        128
      ],
      "id": "8ea41e1a-8282-479d-8739-e7f82eaeb866",
      "name": "Update Topic State",
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "p1yb7OdsllaTAj7J",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "leftValue": "={{ $json.topic_shift_detected }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            },
            {
              "leftValue": "={{ $json.previous_topic_message_count }}",
              "rightValue": 3,
              "operator": {
                "type": "number",
                "operation": "gte"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        3456,
        128
      ],
      "id": "416753cd-b807-4439-9656-0e6e52920895",
      "name": "Should Create Summary?"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT \n  id,\n  role,\n  message,\n  message_original,\n  created_at\nFROM {{ $('Start').first().json.table_prefix }}chat_transcript\nWHERE context_id = '{{ $json.context_id }}'\n  AND id >= {{ $json.previous_topic_start_id }}\n  AND id < {{ $json.current_topic_start_id }}\nORDER BY created_at ASC;",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        3696,
        112
      ],
      "id": "b677c853-992c-4c23-9508-aa642778a9b3",
      "name": "Fetch Topic Messages",
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "p1yb7OdsllaTAj7J",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Prepare messages for summarization\nconst stateData = $('Update Topic State').first().json;\nconst messages = $input.all().map(i => i.json);\n\n// Format conversation\nconst conversation = messages.map(m => {\n  const content = m.message_original || m.message;\n  return `${m.role}: ${content}`;\n}).join('\\n\\n');\n\n// Build summarization prompt\nconst prompt = `Create a concise summary of this conversation topic.\n\nConversation (${messages.length} messages):\n${conversation}\n\nProvide a JSON response (no markdown, no code blocks):\n{\n  \"topic_title\": \"Brief 5-8 word description\",\n  \"main_summary\": \"2-3 sentence overview\",\n  \"key_points\": [\"point 1\", \"point 2\", \"point 3\"],\n  \"decisions_made\": [\"decision 1\"] or [],\n  \"action_items\": [\"action 1\"] or []\n}\n\nGuidelines:\n- Keep concise and focused\n- Capture main ideas and important details\n- Omit greetings and casual chat`;\n\nreturn [{\n  json: {\n    context_id: stateData.context_id,\n    first_message_id: messages[0].id,\n    last_message_id: messages[messages.length - 1].id,\n    message_count: messages.length,\n    previous_topic_name: stateData.previous_topic_name,\n    summarization_prompt: prompt\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3904,
        112
      ],
      "id": "5b3c200e-aada-4876-97f7-92a099b2ae55",
      "name": "Prepare Summarization"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.summarization_prompt }}",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        4096,
        112
      ],
      "id": "83be52c0-a01b-4a35-8c98-cbb40dbe1b8a",
      "name": "Generate Summary"
    },
    {
      "parameters": {
        "jsCode": "// Format the AI summary for storage\nconst summaryInput = $('Prepare Summarization').first().json;\nconst aiOutput = $json.output || '{}';\n\n// Parse AI response\nlet parsed;\ntry {\n  const cleaned = aiOutput\n    .replace(/```json\\n?/g, '')\n    .replace(/```\\n?/g, '')\n    .trim();\n  parsed = JSON.parse(cleaned);\n} catch (e) {\n  console.log('Failed to parse summary:', aiOutput);\n  parsed = {\n    topic_title: summaryInput.previous_topic_name || 'Topic',\n    main_summary: aiOutput.substring(0, 200),\n    key_points: [],\n    decisions_made: [],\n    action_items: []\n  };\n}\n\n// Format the full summary\nlet fullSummary = `${parsed.main_summary}\\n\\n`;\n\nif (parsed.key_points?.length > 0) {\n  fullSummary += `Key Points: ${parsed.key_points.join('; ')}\\n`;\n}\n\nif (parsed.decisions_made?.length > 0) {\n  fullSummary += `Decisions: ${parsed.decisions_made.join('; ')}\\n`;\n}\n\nif (parsed.action_items?.length > 0) {\n  fullSummary += `Actions: ${parsed.action_items.join('; ')}`;\n}\n\nconsole.log('=== TOPIC SUMMARY CREATED ===');\nconsole.log('Title:', parsed.topic_title);\nconsole.log('Messages:', summaryInput.first_message_id, 'to', summaryInput.last_message_id);\nconsole.log('Count:', summaryInput.message_count);\nconsole.log('============================');\n\nreturn [{\n  json: {\n    context_id: summaryInput.context_id,\n    topic_title: parsed.topic_title,\n    topic_summary: fullSummary.trim(),\n    first_message_id: summaryInput.first_message_id,\n    last_message_id: summaryInput.last_message_id,\n    message_count: summaryInput.message_count\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4400,
        112
      ],
      "id": "bb88ca8a-d0f0-43e8-afcb-1bc847dabf83",
      "name": "Format Summary"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO {{ $('Start').first().json.table_prefix }}chat_topic_summaries\n(context_id, topic_title, topic_summary, first_message_id, last_message_id, message_count)\nVALUES (\n  '{{ $json.context_id }}',\n  '{{ String($json.topic_title).replace(/'/g, \"''\") }}',\n  '{{ String($json.topic_summary).replace(/'/g, \"''\") }}',\n  {{ $json.first_message_id }},\n  {{ $json.last_message_id }},\n  {{ $json.message_count }}\n);",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        4592,
        112
      ],
      "id": "b3bb807f-f54a-4a12-8ab1-7ee948c3faae",
      "name": "Insert Summary",
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "p1yb7OdsllaTAj7J",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        4096,
        304
      ],
      "id": "e39b6ff3-3b6f-4b4a-a4f6-286ad1659517",
      "name": "OpenAI Chat Model3",
      "credentials": {
        "openAiApi": {
          "id": "ypHiVnbB3jkc0yAx",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Check for gap between summaries and recent messages\nconst trigger = $('Start').first().json || {};\nconst summaryRows = $('Fetch Topic Summaries').all().map(i => i.json || {});\nconst transcriptRows = $('Fetch Transcript').all().map(i => i.json || {});\n\n// Sort transcript by ID to find oldest recent message\nconst sortedTranscript = transcriptRows\n  .filter(r => r.id)\n  .sort((a, b) => a.id - b.id);\n\nconst oldestRecentMessageId = sortedTranscript.length > 0 ? sortedTranscript[0].id : 999999;\n\n// Find last summary's end message ID\nconst lastSummaryEndId = summaryRows.length > 0 \n  ? Math.max(...summaryRows.map(s => s.last_message_id || 0))\n  : 0;\n\n// Calculate gap\nconst gapStart = lastSummaryEndId + 1;\nconst gapEnd = oldestRecentMessageId - 1;\nconst gapSize = gapEnd - gapStart + 1;\nconst hasGap = gapSize >= 3 && lastSummaryEndId > 0;\n\nconsole.log('=== GAP DETECTION ===');\nconsole.log('Last summary ended at:', lastSummaryEndId);\nconsole.log('Recent window starts at:', oldestRecentMessageId);\nconsole.log('Gap:', gapStart, 'to', gapEnd, '=', gapSize, 'messages');\nconsole.log('Should fill gap:', hasGap);\nconsole.log('====================');\n\nreturn [{\n  json: {\n    context_id: trigger.context_id,\n    has_gap: hasGap,\n    gap_start_id: gapStart,\n    gap_end_id: gapEnd,\n    gap_size: gapSize,\n    summary_rows: summaryRows,\n    transcript_rows: transcriptRows\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2768,
        -80
      ],
      "id": "3b62e171-c629-45ab-8726-0763ffbc1fe2",
      "name": "Detect Gap"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "leftValue": "={{ $json.has_gap }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        2960,
        -80
      ],
      "id": "d692de5f-b90c-4b09-a01c-8bc3784c760d",
      "name": "Should Fill Gap?"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT \n  id,\n  role,\n  message,\n  message_original,\n  created_at\nFROM {{ $('Start').first().json.table_prefix }}chat_transcript\nWHERE context_id = '{{ $json.context_id }}'\n  AND id >= {{ $json.gap_start_id }}\n  AND id <= {{ $json.gap_end_id }}\nORDER BY created_at ASC;",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        3184,
        -288
      ],
      "id": "2d17b08b-c547-45b4-ae24-036c2af11399",
      "name": "Fetch Gap Messages",
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "p1yb7OdsllaTAj7J",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Prepare gap messages for summarization\nconst gapData = $('Should Fill Gap?').first().json;\nconst messages = $input.all().map(i => i.json);\n\n// Format conversation\nconst conversation = messages.map(m => {\n  const content = m.message_original || m.message;\n  return `${m.role}: ${content}`;\n}).join('\\n\\n');\n\n// Build prompt\nconst prompt = `Create a concise summary of this conversation segment.\n\nConversation (${messages.length} messages):\n${conversation}\n\nProvide JSON (no markdown):\n{\n  \"topic_title\": \"5-8 word description\",\n  \"main_summary\": \"2-3 sentences\",\n  \"key_points\": [\"point 1\", \"point 2\"],\n  \"decisions_made\": [],\n  \"action_items\": []\n}\n\nKeep concise and capture main ideas.`;\n\nconsole.log('=== FILLING GAP ===');\nconsole.log('Gap messages:', gapData.gap_start_id, 'to', gapData.gap_end_id);\nconsole.log('Count:', messages.length);\nconsole.log('===================');\n\nreturn [{\n  json: {\n    context_id: gapData.context_id,\n    first_message_id: messages[0].id,\n    last_message_id: messages[messages.length - 1].id,\n    message_count: messages.length,\n    summarization_prompt: prompt,\n    gap_data: gapData\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3360,
        -288
      ],
      "id": "6599666d-29f0-46f8-9a8a-0562e972dd6c",
      "name": "Prepare Gap Summary"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.summarization_prompt }}",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        3568,
        -288
      ],
      "id": "dbc032cf-eb5a-4c05-b94d-6e527dc25c84",
      "name": "Generate Gap Summary"
    },
    {
      "parameters": {
        "jsCode": "// Format gap summary for storage\nconst summaryInput = $('Prepare Gap Summary').first().json;\nconst aiOutput = $json.output || '{}';\n\n// Parse AI response\nlet parsed;\ntry {\n  const cleaned = aiOutput\n    .replace(/```json\\n?/g, '')\n    .replace(/```\\n?/g, '')\n    .trim();\n  parsed = JSON.parse(cleaned);\n} catch (e) {\n  console.log('Failed to parse gap summary:', aiOutput);\n  parsed = {\n    topic_title: 'Gap Summary',\n    main_summary: aiOutput.substring(0, 200),\n    key_points: []\n  };\n}\n\n// Format full summary\nlet fullSummary = `${parsed.main_summary}\\n\\n`;\nif (parsed.key_points?.length > 0) {\n  fullSummary += `Key Points: ${parsed.key_points.join('; ')}`;\n}\n\nconsole.log('=== GAP SUMMARY CREATED ===');\nconsole.log('Title:', parsed.topic_title);\nconsole.log('Messages:', summaryInput.first_message_id, 'to', summaryInput.last_message_id);\nconsole.log('===========================');\n\nreturn [{\n  json: {\n    context_id: summaryInput.context_id,\n    topic_title: parsed.topic_title,\n    topic_summary: fullSummary.trim(),\n    first_message_id: summaryInput.first_message_id,\n    last_message_id: summaryInput.last_message_id,\n    message_count: summaryInput.message_count,\n    gap_data: summaryInput.gap_data\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3936,
        -288
      ],
      "id": "15495fd4-094f-4317-9034-b63e6f299755",
      "name": "Format Gap Summary"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO {{ $('Start').first().json.table_prefix }}chat_topic_summaries\n(context_id, topic_title, topic_summary, first_message_id, last_message_id, message_count)\nVALUES (\n  '{{ $json.context_id }}',\n  '{{ String($json.topic_title).replace(/'/g, \"''\") }}',\n  '{{ String($json.topic_summary).replace(/'/g, \"''\") }}',\n  {{ $json.first_message_id }},\n  {{ $json.last_message_id }},\n  {{ $json.message_count }}\n);",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        4144,
        -288
      ],
      "id": "3bf5e998-0ad8-4ed2-9ebd-fc09d18fcfb0",
      "name": "Insert Gap Summary",
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "p1yb7OdsllaTAj7J",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Merge summaries - handle both paths (gap filled or not)\nconst inputData = $input.first().json;\n\n// Determine which path we came from\nlet summaryRows = [];\nlet transcriptRows = [];\n\nif (inputData.gap_data) {\n  // Came from gap-filling path - has gap_data passed through\n  summaryRows = inputData.gap_data.summary_rows || [];\n  transcriptRows = inputData.gap_data.transcript_rows || [];\n  \n  // Add the newly created gap summary\n  summaryRows.push({\n    topic_title: inputData.topic_title,\n    topic_summary: inputData.topic_summary,\n    first_message_id: inputData.first_message_id,\n    last_message_id: inputData.last_message_id,\n    message_count: inputData.message_count\n  });\n  \n  // Re-sort by message range\n  summaryRows.sort((a, b) => a.first_message_id - b.first_message_id);\n  \n} else {\n  // Came from no-gap path - use data as-is\n  summaryRows = inputData.summary_rows || [];\n  transcriptRows = inputData.transcript_rows || [];\n}\n\nreturn [{\n  json: {\n    summary_rows: summaryRows,\n    transcript_rows: transcriptRows\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4320,
        -64
      ],
      "id": "9ae85a3a-73b5-467e-a583-746068a8109f",
      "name": "Merge Gap Summary"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        3568,
        -144
      ],
      "id": "3c4999b5-6556-4cf6-8175-3be7621e822d",
      "name": "OpenAI Chat Model4",
      "credentials": {
        "openAiApi": {
          "id": "ypHiVnbB3jkc0yAx",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        160,
        144
      ],
      "id": "6e80b654-11a8-4fcf-8a1d-5e2ad6727e94",
      "name": "When clicking ‘Execute workflow’"
    },
    {
      "parameters": {
        "inputSource": "jsonExample",
        "jsonExample": "{\n  \"context_id\": \"823f85559ab443eeabb3887ead1db47b\",\n  \"table_prefix\": \"ura_dev_\",\n  \"userMessage\": \"I like fishing\",\n  \"assistantResponse\": \"That's great! Fishing is a wonderful hobby...\",\n  \"context\": \"{\\\"recent_messages\\\":[{\\\"id\\\":1,\\\"role\\\":\\\"user\\\",\\\"content\\\":\\\"hello\\\",\\\"was_truncated\\\":false},{\\\"id\\\":2,\\\"role\\\":\\\"assistant\\\",\\\"content\\\":\\\"hi there\\\",\\\"was_truncated\\\":false}],\\\"long_term_memories\\\":[{\\\"type\\\":\\\"preference\\\",\\\"content\\\":\\\"User likes fishing\\\"}]}\"\n}"
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        160,
        -80
      ],
      "id": "f9528f43-2883-49ec-9d60-ed74c71a703b",
      "name": "Entry"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "0eec5cdd-dd64-4e0a-aa6f-9c50e2c7c878",
              "name": "=context_id",
              "value": "{{ $json.context_id }}",
              "type": "string"
            },
            {
              "id": "79c75c46-1abf-47a7-abe7-373f57b478a0",
              "name": "=table_prefix",
              "value": "={{ $json.table_prefix }}",
              "type": "string"
            },
            {
              "id": "5ba76ac2-3f1c-48ab-8770-567267ca2f71",
              "name": "userMessage",
              "value": "={{ $json.userMessage }}",
              "type": "string"
            },
            {
              "id": "cb2f476d-0726-4a7a-95a8-42a9e6630428",
              "name": "assistantResponse",
              "value": "={{ $json.assistantResponse }}",
              "type": "string"
            },
            {
              "id": "638351b1-eaa8-4bdd-8ecb-fbcebc1ec1c1",
              "name": "context",
              "value": "={{ $json.context }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        528,
        -80
      ],
      "id": "6fdc471c-37c9-409b-9ab9-d885823b2f74",
      "name": "Start"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "0eec5cdd-dd64-4e0a-aa6f-9c50e2c7c878",
              "name": "context_id",
              "value": "michaelfY0bPv0HuPsz",
              "type": "string"
            },
            {
              "id": "79c75c46-1abf-47a7-abe7-373f57b478a0",
              "name": "table_prefix",
              "value": "ura_dev_",
              "type": "string"
            },
            {
              "id": "5ba76ac2-3f1c-48ab-8770-567267ca2f71",
              "name": "userMessage",
              "value": "My cat is sneezing sometimes.",
              "type": "string"
            },
            {
              "id": "cb2f476d-0726-4a7a-95a8-42a9e6630428",
              "name": "assistantResponse",
              "value": "I'm sorry to hear your cat is sneezing.",
              "type": "string"
            },
            {
              "id": "638351b1-eaa8-4bdd-8ecb-fbcebc1ec1c1",
              "name": "context",
              "value": "={\"recent_messages\":[{\"id\":135,\"role\":\"user\",\"content\":\"Hahahah, no, I love my cat, but I would not like to drink from the same glass.\",\"was_truncated\":false},{\"id\":136,\"role\":\"assistant\",\"content\":\"That’s totally understandable! Cats have their own unique way of sharing space, but some boundaries like the glass are definitely good to keep. Does your cat try to sneak a sip sometimes?\",\"was_truncated\":false},{\"id\":138,\"role\":\"assistant\",\"content\":\"Cats do have a knack for getting into everything, especially glasses of water! It sounds like your cat is quite curious and thirsty. Maybe you could try giving your cat its own water bowl nearby—that way, it might be less interested in your glass. Do you already have a favorite spot for your cat’s water?\",\"was_truncated\":false},{\"id\":137,\"role\":\"user\",\"content\":\"Yes, since I got the cat I have to cover my glas. Otherwise it would drink from my glas the very moment that I don't pay attention\",\"was_truncated\":false},{\"id\":139,\"role\":\"user\",\"content\":\"Yes, there is actually just one spot that the cat likes her water. It's in my living room.\",\"was_truncated\":false},{\"id\":140,\"role\":\"assistant\",\"content\":\"That's adorable! Cats can be quite particular about their water spots. Do you have a special bowl or fountain there that she prefers? Sometimes the location, water freshness, or even the type of bowl can make a big difference for them.\",\"was_truncated\":false},{\"id\":141,\"role\":\"user\",\"content\":\"Yes, my cat will only accept to drink water from a big drinking glas.\",\"was_truncated\":false},{\"id\":142,\"role\":\"assistant\",\"content\":\"That's quite interesting! Cats can be quite particular about their water sources. Using a big drinking glass sounds like a simple solution. Just make sure the glass is clean and filled with fresh water regularly. If you want, I can also suggest some tips to encourage your cat to drink more water or make sure the water stays fresh longer. Would you like that?\",\"was_truncated\":false},{\"id\":143,\"role\":\"user\",\"content\":\"I always think about giving my cat fresh water. I don't forget that.\",\"was_truncated\":false},{\"id\":144,\"role\":\"assistant\",\"content\":\"That's wonderful! Making sure your cat always has fresh water is very important for their health. If you'd like, I can help you set reminders or suggest ways to keep the water fresh and appealing for your cat. Would you like some tips?\",\"was_truncated\":false}],\"topic_summaries\":[{\"summary\":\"{\\n  \\\"topic_title\\\": \\\"Cat's Unique Preferences and Care\\\",\\n  \\\"main_summary\\\": \\\"The user shares how their cat enjoys being brushed, especially on the back and under the chin, which makes it purr loudly. Additionally, the cat prefers drinking water from glasses rather than pet-specific bowls. The conversation highlights the importance of catering to the cat's individual preferences for its comfort and health.\\\",\\n  \\\"key_points\\\": [\\n    \\\"Cat enjoys being brushed and tickled, showing signs of happiness like purring.\\\",\\n    \\\"Cat prefers drinking from glasses over fountains or bowls.\\\"\\n  ]\\n}\",\"topic_title\":\"Gap Summary\",\"message_count\":10,\"message_range\":[125,134]},{\"summary\":\"The user describes their cat as an affectionate cuddler who enjoys crawling under their jumper. The assistant provides safety tips for playing with cats, including avoiding scratches, toxic objects, and overstimulation.\\n\\nKey Points: Cat likes to cuddle and hide under clothing; Playing safely involves preventing scratches, choking hazards, and overstimulation\",\"topic_title\":\"Cat cuddling and safe play tips\",\"message_count\":8,\"message_range\":[117,124]},{\"summary\":\"The conversation discusses Amazon's special sale events such as Prime Day, Black Friday, and Cyber Monday, highlighting opportunities to purchase discounted Christmas gifts. It also covers the possibility of using Amazon's gift wrapping and direct delivery services to send presents conveniently. Assistance was offered to find deals and information on gift services.\\n\\nKey Points: Amazon holds special sales including Prime Day, Black Friday, and Cyber Monday.; These events are ideal for buying discounted holiday gifts.; Amazon provides gift wrapping and direct delivery options.\\nActions: Assist user in finding current Amazon deals and gift options\",\"topic_title\":\"Amazon special sales and gift options\",\"message_count\":6,\"message_range\":[111,116]},{\"summary\":\"The user remembered to refuel their car and discussed the importance of avoiding running out of gas, especially on the highway. They highlighted how modern technology, like fuel monitoring in BMW cars and smartphone apps, simplifies managing fuel levels and enhances driving safety.\\n\\nKey Points: Running out of gas on the highway is dangerous and stressful; Modern cars provide effective fuel level monitoring; BMW app offers convenient real-time fuel data\\nActions: Fill up the car with gas today\",\"topic_title\":\"Car Fuel Management and Technology\",\"message_count\":6,\"message_range\":[103,108]}],\"long_term_memories\":[]}\\n",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        336,
        144
      ],
      "id": "d39418cd-3dd8-4491-bfdd-da89df415424",
      "name": "Test Values"
    }
  ],
  "pinData": {},
  "connections": {
    "Memory Manager": {
      "main": [
        [
          {
            "node": "Prepare Messages",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Next Context": {
      "main": [
        [
          {
            "node": "Upsert Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Messages": {
      "main": [
        [
          {
            "node": "Check If Summary Needed",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check If Summary Needed": {
      "main": [
        [
          {
            "node": "Summarize Long Message",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Use Original Message",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Summarize Long Message": {
      "main": [
        [
          {
            "node": "Combine Message with Summary",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Combine Message with Summary": {
      "main": [
        [
          {
            "node": "Merge Messages",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Use Original Message": {
      "main": [
        [
          {
            "node": "Merge Messages",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge Messages": {
      "main": [
        [
          {
            "node": "Insert Transcript",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Memory Manager",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "Summarize Long Message",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Insert Transcript": {
      "main": [
        [
          {
            "node": "Fetch Transcript",
            "type": "main",
            "index": 0
          },
          {
            "node": "Fetch Recent for Detection",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Transcript": {
      "main": [
        [
          {
            "node": "Fetch Topic Summaries",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Topic Summaries": {
      "main": [
        [
          {
            "node": "Detect Gap",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Recent for Detection": {
      "main": [
        [
          {
            "node": "Prepare Detection Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Detect Topic Shift": {
      "main": [
        [
          {
            "node": "Log Detection Result",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Log Detection Result": {
      "main": [
        [
          {
            "node": "Update Topic State",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Detect Topic Shift",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Detection Data": {
      "main": [
        [
          {
            "node": "Detect Topic Shift",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Update Topic State": {
      "main": [
        [
          {
            "node": "Should Create Summary?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Should Create Summary?": {
      "main": [
        [
          {
            "node": "Fetch Topic Messages",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Topic Messages": {
      "main": [
        [
          {
            "node": "Prepare Summarization",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Summarization": {
      "main": [
        [
          {
            "node": "Generate Summary",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Summary": {
      "main": [
        [
          {
            "node": "Format Summary",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Summary": {
      "main": [
        [
          {
            "node": "Insert Summary",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "Generate Summary",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Detect Gap": {
      "main": [
        [
          {
            "node": "Should Fill Gap?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Should Fill Gap?": {
      "main": [
        [
          {
            "node": "Fetch Gap Messages",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Merge Gap Summary",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Gap Messages": {
      "main": [
        [
          {
            "node": "Prepare Gap Summary",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Gap Summary": {
      "main": [
        [
          {
            "node": "Generate Gap Summary",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Gap Summary": {
      "main": [
        [
          {
            "node": "Format Gap Summary",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Gap Summary": {
      "main": [
        [
          {
            "node": "Insert Gap Summary",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Insert Gap Summary": {
      "main": [
        [
          {
            "node": "Merge Gap Summary",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Gap Summary": {
      "main": [
        [
          {
            "node": "Build Next Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model4": {
      "ai_languageModel": [
        [
          {
            "node": "Generate Gap Summary",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "When clicking ‘Execute workflow’": {
      "main": [
        [
          {
            "node": "Test Values",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Entry": {
      "main": [
        [
          {
            "node": "Start",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Start": {
      "main": [
        [
          {
            "node": "Memory Manager",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Test Values": {
      "main": [
        [
          {
            "node": "Start",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "996f43b6-a724-4af5-8a2c-36f8c5781af7",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "7ac72ab13b8f564b4e52fe865fd322b93ff4a198e7d01a343aa643a3d940b098"
  },
  "id": "e7XF3f8ZZCeSZyw0",
  "tags": []
}