{
  "name": "Table Memory Chat Bot Process - Enhanced",
  "nodes": [
    {
      "parameters": {
        "promptType": "define",
        "text": "=Analyze if this conversation contains information worth remembering long-term.\n\nCurrent context:\n={{ $json.context }}\n\nLatest exchange:\nUser: {{ $json.userMessage }}\nAssistant: {{ $json.assistantResponse }}\n\nRespond with ONLY valid JSON:\n{\"should_update\": true, \"new_memories\": [{\"type\": \"preference\", \"content\": \"User likes pizza\"}], \"remove_indices\": []}\n\nOnly create memories for important lasting information (preferences, facts, goals). Not for casual greetings.",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        -1776,
        112
      ],
      "id": "8fdfa825-8466-4951-9a7b-df7c0a90801f",
      "name": "Memory Manager"
    },
    {
      "parameters": {
        "jsCode": "// Configuration for context rebuilding\nconst MAX_MESSAGES = 20; // total entries (user + assistant)\nconst MAX_CHAR_COUNT = 100000; // hard ceiling for combined character count\nconst SUMMARY_SUFFIX = ' ... [truncated]';\n\n// Gather latest interaction data\nconst contextId = $('When Executed by Another Workflow').item.json.context_id;\n\n// Memory manager output\nconst memoryOutput = $input.item.json.output;\n\n// Parse prior context safely\nlet context = { recent_messages: [], long_term_memories: [] };\nconst contextData = $('When Executed by Another Workflow').item.json.context;\n\nif (contextData) {\n  try {\n    if (typeof contextData === 'object') {\n      context = contextData;\n    } else if (typeof contextData === 'string') {\n      const trimmed = contextData.trim();\n      if (trimmed && trimmed !== 'null' && trimmed !== 'undefined') {\n        context = JSON.parse(trimmed);\n      }\n    }\n  } catch (e) {\n    console.log('Error parsing context, using empty context:', e.message);\n  }\n}\n\nif (!Array.isArray(context.recent_messages)) {\n  context.recent_messages = [];\n} else {\n  context.recent_messages = context.recent_messages\n    .filter((entry) => entry && typeof entry === 'object')\n    .map((entry) => ({\n      role: entry.role || 'assistant',\n      content: typeof entry.content === 'string' ? entry.content : ''\n    }));\n}\n\nif (!Array.isArray(context.long_term_memories)) {\n  context.long_term_memories = [];\n}\n\nconst transcriptItems = $items('Fetch Transcript') || [];\nconst transcripts = transcriptItems\n  .map((item) => item.json || {})\n  .filter((entry) => entry && (!entry.context_id || entry.context_id === contextId))\n  .sort((a, b) => {\n    const toTimestamp = (value) => {\n      if (!value) {\n        return 0;\n      }\n      const parsed = Date.parse(value);\n      if (!Number.isNaN(parsed)) {\n        return parsed;\n      }\n      const numeric = Number(value);\n      return Number.isFinite(numeric) ? numeric : 0;\n    };\n    const aTime = toTimestamp(a.created_at ?? a.created_at ?? a.updated_at ?? a.updated_at);\n    const bTime = toTimestamp(b.created_at ?? b.created_at ?? b.updated_at ?? b.updated_at);\n    return bTime - aTime;\n  });\n\nconst rebuiltMessages = [];\nlet totalChars = 0;\nlet stopAdding = false;\n\nconst addMessage = (role, originalContent) => {\n  if (stopAdding || rebuiltMessages.length >= MAX_MESSAGES) {\n    stopAdding = true;\n    return;\n  }\n\n  let content = typeof originalContent === 'string' ? originalContent.trim() : '';\n  if (!content) {\n    return;\n  }\n\n  let summaryAttempted = false;\n\n  while (true) {\n    if (totalChars + content.length <= MAX_CHAR_COUNT) {\n      rebuiltMessages.push({ role, content });\n      totalChars += content.length;\n      return;\n    }\n\n    if (summaryAttempted) {\n      stopAdding = true;\n      return;\n    }\n\n    summaryAttempted = true;\n    const available = MAX_CHAR_COUNT - totalChars;\n    if (available <= SUMMARY_SUFFIX.length) {\n      stopAdding = true;\n      return;\n    }\n\n    const sliceLength = Math.max(available - SUMMARY_SUFFIX.length, 0);\n    content = `${content.slice(0, sliceLength)}${SUMMARY_SUFFIX}`;\n  }\n};\n\nif (transcripts.length > 0) {\n  for (const entry of transcripts) {\n    if (stopAdding || rebuiltMessages.length >= MAX_MESSAGES) {\n      break;\n    }\n    const role = entry.role === 'assistant' ? 'assistant' : 'user';\n    addMessage(role, entry.message);\n  }\n} else if (context.recent_messages.length > 0) {\n  // Fall back to existing context if no transcript rows are available\n  for (const entry of context.recent_messages.slice(-MAX_MESSAGES)) {\n    addMessage(entry.role === 'assistant' ? 'assistant' : 'user', entry.content);\n  }\n}\n\ncontext.recent_messages = rebuiltMessages.reverse();\n\n// Update long-term memory decisions\nlet memoryUpdate = { should_update: false, new_memories: [], remove_indices: [] };\ntry {\n  const cleaned = memoryOutput.replace(/```json\\n?/g, '').replace(/```/g, '').trim();\n  memoryUpdate = JSON.parse(cleaned);\n} catch (e) {\n  console.log('No memory update');\n}\n\nif (memoryUpdate.should_update && Array.isArray(memoryUpdate.new_memories)) {\n  context.long_term_memories.push(...memoryUpdate.new_memories);\n}\n\nreturn {\n  json: {\n    context_id: contextId,\n    context: JSON.stringify(context)\n  }\n};\r\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -416,
        112
      ],
      "id": "7466fda9-7a4e-4dca-9b59-efced41885f0",
      "name": "Build Next Context"
    },
    {
      "parameters": {
        "jsCode": "// Configuration\nconst MESSAGE_LENGTH_THRESHOLD = 5000;\nconst TRUNCATE_LENGTH = 1000;\nconst TRUNCATION_SUFFIX = '... [truncated] Message Summary: ';\n\n// Get input data\nconst contextId = $('When Executed by Another Workflow').item.json.context_id;\nconst userMessage = $('When Executed by Another Workflow').item.json.userMessage;\nconst assistantResponse = $('When Executed by Another Workflow').item.json.assistantResponse;\n\n// Process user message\nlet userItem = null;\nif (typeof userMessage === 'string' && userMessage.trim()) {\n  const originalMessage = userMessage.trim();\n  const messageLength = originalMessage.length;\n  \n  userItem = {\n    context_id: contextId,\n    role: 'user',\n    message_original: originalMessage,\n    needs_summary: messageLength > MESSAGE_LENGTH_THRESHOLD,\n    truncated_message: messageLength > MESSAGE_LENGTH_THRESHOLD \n      ? originalMessage.substring(0, TRUNCATE_LENGTH) + TRUNCATION_SUFFIX\n      : null,\n    message: messageLength <= MESSAGE_LENGTH_THRESHOLD ? originalMessage : null\n  };\n}\n\n// Process assistant message\nlet assistantItem = null;\nif (typeof assistantResponse === 'string' && assistantResponse.trim()) {\n  const originalMessage = assistantResponse.trim();\n  const messageLength = originalMessage.length;\n  \n  assistantItem = {\n    context_id: contextId,\n    role: 'assistant',\n    message_original: originalMessage,\n    needs_summary: messageLength > MESSAGE_LENGTH_THRESHOLD,\n    truncated_message: messageLength > MESSAGE_LENGTH_THRESHOLD \n      ? originalMessage.substring(0, TRUNCATE_LENGTH) + TRUNCATION_SUFFIX\n      : null,\n    message: messageLength <= MESSAGE_LENGTH_THRESHOLD ? originalMessage : null\n  };\n}\n\n// Return items for processing\nconst items = [];\nif (userItem) items.push({ json: userItem });\nif (assistantItem) items.push({ json: assistantItem });\n\nreturn items;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1424,
        112
      ],
      "id": "00e59f45-8b46-4f0e-9d14-ed6a58290f10",
      "name": "Prepare Messages"
    },
    {
      "parameters": {
        "conditions": {
          "boolean": [
            {
              "value1": "={{ $json.needs_summary }}",
              "value2": true
            }
          ]
        }
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 1,
      "position": [
        -1216,
        112
      ],
      "id": "d3f4e8a5-2b6c-4d7e-8f9a-1b2c3d4e5f6a",
      "name": "Check If Summary Needed"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Create a concise summary of the following message. The summary MUST be 1000 characters or less. Focus on the key points and main ideas.\n\nOriginal message:\n{{ $json.message_original }}\n\nProvide ONLY the summary text, no additional formatting or explanation.",
        "options": {
          "maxTokens": 400
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        -1008,
        -80
      ],
      "id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
      "name": "Summarize Long Message"
    },
    {
      "parameters": {
        "jsCode": "// Get the summary from the LLM\nconst summary = $input.item.json.output || '';\n\n// Ensure summary doesn't exceed 1000 characters\nconst trimmedSummary = summary.substring(0, 1000);\n\n// Combine truncated message with summary\nconst finalMessage = $json.truncated_message + trimmedSummary;\n\n// Return the complete item with the processed message\nreturn {\n  json: {\n    context_id: $json.context_id,\n    role: $json.role,\n    message_original: $json.message_original,\n    message: finalMessage\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -800,
        -80
      ],
      "id": "b2c3d4e5-f6a7-8901-bcde-f12345678901",
      "name": "Combine Message with Summary"
    },
    {
      "parameters": {
        "jsCode": "// Message doesn't need summary, use original as-is\nreturn {\n  json: {\n    context_id: $json.context_id,\n    role: $json.role,\n    message_original: $json.message_original,\n    message: $json.message\n  }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1008,
        304
      ],
      "id": "c3d4e5f6-a7b8-9012-cdef-123456789012",
      "name": "Use Original Message"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.merge",
      "typeVersion": 2.1,
      "position": [
        -608,
        112
      ],
      "id": "d4e5f6a7-b8c9-0123-defa-234567890123",
      "name": "Merge Messages"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4o-mini",
          "mode": "list",
          "cachedResultName": "gpt-4o-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -1776,
        304
      ],
      "id": "4e6abbb5-2914-44c8-8787-ed7c8b628b3f",
      "name": "OpenAI Chat Model1",
      "credentials": {
        "openAiApi": {
          "id": "ypHiVnbB3jkc0yAx",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4o-mini",
          "mode": "list",
          "cachedResultName": "gpt-4o-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -1008,
        -272
      ],
      "id": "e5f6a7b8-c9d0-1234-efab-345678901234",
      "name": "OpenAI Chat Model2",
      "credentials": {
        "openAiApi": {
          "id": "ypHiVnbB3jkc0yAx",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "inputSource": "jsonExample",
        "jsonExample": "{\n  \"context_id\": \"823f85559ab443eeabb3887ead1db47b\",\n  \"table_prefix\": \"ura_dev_\",\n  \"userMessage\": \"I like fishing\",\n  \"assistantResponse\": \"That's great! Fishing is a wonderful hobby...\",\n  \"context\": \"{\\\"recent_messages\\\":[{\\\"role\\\":\\\"user\\\",\\\"content\\\":\\\"hello\\\"},{\\\"role\\\":\\\"assistant\\\",\\\"content\\\":\\\"hi there\\\"}],\\\"long_term_memories\\\":[{\\\"type\\\":\\\"preference\\\",\\\"content\\\":\\\"User likes fishing\\\"}]}\"\n}"
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        -1984,
        112
      ],
      "id": "8cea47a5-2d7f-4377-a08c-5071021af863",
      "name": "When Executed by Another Workflow"
    },
    {
      "parameters": {
        "content": "Enhanced Message Processing:\n- Messages > 5000 chars get truncated to 1000 chars + AI summary\n- Original always stored in message_original column\n- Processed/truncated version in message column\n- Automatic length calculation via DB triggers",
        "height": 150,
        "width": 350
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -1424,
        -200
      ],
      "typeVersion": 1,
      "id": "bb53ba4d-5754-4ef1-9d07-b8a4e0fc89b8",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO {{ $('When Executed by Another Workflow').first().json.table_prefix }}chat_transcript\n(context_id, role, message, message_original) VALUES (\n  '{{ String($json.context_id).replace(/'/g, \"''\") }}',\n  '{{ String($json.role).replace(/'/g, \"''\") }}',\n  '{{ String($json.message).replace(/'/g, \"''\") }}',\n  '{{ String($json.message_original).replace(/'/g, \"''\") }}'\n);\n",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -416,
        304
      ],
      "id": "13f668b0-adfb-4db1-a02f-8b6616959632",
      "name": "Insert Transcript",
      "credentials": {
        "postgres": {
          "id": "p1yb7OdsllaTAj7J",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT id, context_id, role, message, message_original, message_length, message_original_length, created_at, updated_at \nFROM {{ $('When Executed by Another Workflow').item.json.table_prefix }}chat_transcript \nWHERE context_id = '{{ $('When Executed by Another Workflow').item.json.context_id }}' \nORDER BY created_at ASC;",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -208,
        304
      ],
      "id": "3bfd047a-90b7-4b83-877c-18c7583d1329",
      "name": "Fetch Transcript",
      "credentials": {
        "postgres": {
          "id": "p1yb7OdsllaTAj7J",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO {{ $('When Executed by Another Workflow').first().json.table_prefix }}chat_contexts\n(context_id, context)\nVALUES (\n  '{{ $json.context_id }}',\n  COALESCE(\n    NULLIF($$\n      {{ typeof $json.context === 'string'\n          ? $json.context\n          : JSON.stringify($json.context || {}) }}\n    $$, '')::jsonb,\n    '{}'::jsonb\n  )\n)\nON CONFLICT (context_id) DO UPDATE SET\n  context    = EXCLUDED.context,\n  \"updated_at\" = timezone('utc'::text, now());\n",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -208,
        112
      ],
      "id": "7dc7a75e-441b-4206-90f5-e2124d514b7f",
      "name": "Upsert Context",
      "credentials": {
        "postgres": {
          "id": "p1yb7OdsllaTAj7J",
          "name": "Postgres account"
        }
      }
    }
  ],
  "pinData": {},
  "connections": {
    "Memory Manager": {
      "main": [
        [
          {
            "node": "Prepare Messages",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Memory Manager",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "Summarize Long Message",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "When Executed by Another Workflow": {
      "main": [
        [
          {
            "node": "Memory Manager",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Messages": {
      "main": [
        [
          {
            "node": "Check If Summary Needed",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check If Summary Needed": {
      "main": [
        [
          {
            "node": "Summarize Long Message",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Use Original Message",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Summarize Long Message": {
      "main": [
        [
          {
            "node": "Combine Message with Summary",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Combine Message with Summary": {
      "main": [
        [
          {
            "node": "Merge Messages",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Use Original Message": {
      "main": [
        [
          {
            "node": "Merge Messages",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge Messages": {
      "main": [
        [
          {
            "node": "Insert Transcript",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Next Context": {
      "main": [
        [
          {
            "node": "Upsert Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Insert Transcript": {
      "main": [
        [
          {
            "node": "Fetch Transcript",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Transcript": {
      "main": [
        [
          {
            "node": "Build Next Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "enhanced-v2",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "7ac72ab13b8f564b4e52fe865fd322b93ff4a198e7d01a343aa643a3d940b098"
  },
  "id": "e7XF3f8ZZCeSZyw0",
  "tags": []
}
